=======
# 学习笔记
# 目录
![](https://p1.ssl.qhimg.com/t01c3f58f10448fc470.jpg)
----
***宋雨琦姐姐***
---
<https://p1.ssl.qhimg.com/t01c3f58f10448fc470.jpg>
--------
***网址***
---
```python
import requests

```
这是一个实例：`import sanqnwrp`
> 来自大人
> 啊佛
> fjoia
> 
> ejgw
>
> 
> jweg
>
>> 文件合同工w
> rey
> 
>>> erwjt
> wseth
> 
> rfar


* 我的
* 你的
+ 大物
+ 没武器
- wtw
- dtu
1. afnw
2. warm
3. 11454

2017.544.14  
awofd<br>
awfdiw

名字| 学号 |成绩
:-:|:--:|:-:
小明|1|98
peter|2|100
小红|3|78

跳转到[目录](#宋雨琦姐姐)


有关所有HTML[1]


[^1]nsgnsgse
$\sqrt{x^{2}}$

![](https://p1.ssl.qhimg.com/t01c3f58f10448fc470.jpg)
<a href="超链接地址" title="超链接title">超链接显示名</a>

sfgidfi[^1]

[^1]:

$a^3_{2}$









































## 爬虫知识总结
### 我目前已经掌握的部分爬虫知识：
> 我们使用爬虫会遇到的情况
>> * 我们要爬的资源就在网页源代码里
> 
>> * 我们要爬的东西不在页面源代码里，需要去找到真正加载数据的那个请求，然后去提取数据

---
需要注意的是，网页源代码与开发者工具里的element不是一会事！！！element是页面源代码经过浏览器的加工后（实时体现）  
而我们写的爬虫程序拿到的是页面源代码！！！一定要以页面源代码为准！！！  
但是可以将element当做参考，结合一下效率会更高（element里有个查找的功能，可以快速定位所需要的东西的位置）  
---
下面是我们未来写爬虫最主要用到工具
> 开发者工具
>> element
>>> sdsgs
>> network
>>> 
>> resource
>>> sds
>> console
>>> 


